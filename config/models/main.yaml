# Hydra Group Configuration for Models (Located in config/models/main.yaml)

architect_default:
  _target_: "builtins.dict" # Using dict as a placeholder if no specific class is needed
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "deepseek/deepseek-chat-v3-0324:free"
  fallback: "gemini/gemini-2.5-pro"

maestro_default:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "deepseek/deepseek-chat-v3-0324:free"
  fallback: "gemini/gemini-2.5-pro"

objective_generator:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "deepseek/deepseek-chat-v3-0324:free"
  fallback: "gemini/gemini-2.5-pro"

capacitation_generator:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "deepseek/deepseek-chat-v3-0324:free"
  fallback: "gemini/gemini-2.5-pro"

error_analyzer:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "deepseek/deepseek-chat-v3-0324:free"
  fallback: "gemini/gemini-2.5-pro"

code_reviewer:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "google/gemma-7b-it:free"
  fallback: "deepseek/deepseek-chat-v3-0324:free"

log_analyzer_default:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "google/gemma-7b-it:free"
  fallback: "deepseek/deepseek-chat-v3-0324:free"

debt_hunter_default:
  _target_: "builtins.dict"
  temperature: ${default_model_settings.temperature}
  max_tokens: ${default_model_settings.max_tokens}
  primary: "google/gemma-7b-it:free"
  fallback: "deepseek/deepseek-chat-v3-0324:free"