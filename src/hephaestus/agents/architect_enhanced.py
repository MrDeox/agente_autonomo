"""
Enhanced Architect Agent - Pilot implementation using new modular architecture
"""

import asyncio
from typing import Optional, Dict, Any, Tuple

from hephaestus.agents.enhanced_base import EnhancedBaseAgent
from hephaestus.agents.base import AgentCapability
from hephaestus.utils.llm_manager import llm_call_with_metrics


class ArchitectAgentEnhanced(EnhancedBaseAgent):
    """
    Enhanced Architect Agent using the new modular architecture.
    
    This is a pilot implementation demonstrating:
    - Automatic dependency injection
    - Standardized LLM calls with retry and metrics
    - Caching
    - Configuration management
    - Comprehensive error handling
    """
    
    def get_default_capabilities(self) -> list:
        """Get default capabilities for the Architect Agent."""
        return [
            AgentCapability.ARCHITECTURE_DESIGN,
            AgentCapability.CODE_ANALYSIS,
            AgentCapability.LONG_TERM_PLANNING
        ]
    
    async def execute(self, objective: str) -> Tuple[bool, Optional[str]]:
        """
        Execute an objective using the enhanced architecture.
        
        Args:
            objective: The objective to execute
            
        Returns:
            Tuple of (success, error_message)
        """
        self.logger.info(f"🏗️ ArchitectAgent executing: {objective}")
        
        # This would typically involve planning, execution, etc.
        # For the pilot, we'll just demonstrate the enhanced capabilities
        try:
            # Simulate some planning work
            plan_result = await self.create_execution_plan(objective)
            
            if not plan_result:
                return False, "Failed to create execution plan"
            
            self.logger.info("✅ ArchitectAgent execution completed successfully")
            return True, None
            
        except Exception as e:
            error_message = self.handle_error(e, "execute")
            return False, error_message
    
    @llm_call_with_metrics
    async def plan_action(self, 
                        objective: str, 
                        manifest: str, 
                        file_content_context: str = "") -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
        """
        Create an action plan using the enhanced LLM call system.
        
        Args:
            objective: The objective to plan for
            manifest: Project manifest
            file_content_context: Additional file context
            
        Returns:
            Tuple of (plan_dict, error_message)
        """
        # Validate inputs
        validation_error = self.validate_required_params(
            {'objective': objective, 'manifest': manifest},
            ['objective', 'manifest']
        )
        if validation_error:
            return None, validation_error
        
        # Sanitize inputs
        objective = self.sanitize_string(objective)
        manifest = self.sanitize_string(manifest)
        file_content_context = self.sanitize_string(file_content_context)
        
        # Check cache first
        cache_key = f"plan_{hash(objective + manifest)}"
        cached_plan = self.get_cached_result(cache_key)
        if cached_plan:
            self.logger.info("Using cached plan")
            return cached_plan, None
        
        # Build prompt
        prompt = self._build_plan_prompt(objective, manifest, file_content_context)
        
        # Make LLM call with automatic retry and metrics
        plan_json, error = await self.llm_call_json(prompt)
        
        if error:
            return None, error
        
        if not plan_json:
            return None, "No plan generated by LLM"
        
        # Validate plan structure
        validation_error = self._validate_plan_structure(plan_json)
        if validation_error:
            return None, validation_error
        
        # Cache the successful plan
        self.set_cached_result(cache_key, plan_json, ttl=1800)  # Cache for 30 minutes
        
        self.logger.info(f"✅ Generated plan with {len(plan_json.get('patches', []))} patches")
        return plan_json, None
    
    async def create_execution_plan(self, objective: str) -> Optional[Dict[str, Any]]:
        """
        Create an execution plan for the objective.
        
        Args:
            objective: The objective to plan for
            
        Returns:
            Execution plan dictionary or None if failed
        """
        # This is a simplified version for the pilot
        # In the real implementation, this would read manifests, analyze context, etc.
        
        try:
            # Simulate manifest loading
            manifest = await self.cached_operation(
                "project_manifest",
                self._load_project_manifest,
                ttl=300  # Cache for 5 minutes
            )
            
            # Create action plan
            plan, error = await self.plan_action(objective, manifest)
            
            if error:
                self.logger.error(f"Failed to create plan: {error}")
                return None
            
            return plan
            
        except Exception as e:
            self.handle_error(e, "create_execution_plan")
            return None
    
    def _build_plan_prompt(self, objective: str, manifest: str, context: str) -> str:
        """
        Build the prompt for plan generation.
        
        Args:
            objective: The objective
            manifest: Project manifest
            context: Additional context
            
        Returns:
            Formatted prompt string
        """
        prompt = f"""
You are the Software Architect of the Hephaestus agent. Your task is to take the high-level objective and, based on the project manifest and any additional file content provided, create a JSON patch plan to modify the files.

[OBJECTIVE]
{objective}

[PROJECT MANIFEST]
{manifest}

[ADDITIONAL CONTEXT FROM FILE READ]
{context}

[YOUR TASK]
Create a JSON plan with a list of "patches" to apply.

Each patch must have:
- "file_path": The path to the file to modify
- "action": Either "create", "modify", or "delete"
- "content": The new content for the file (for create/modify actions)
- "description": A brief description of what this patch does

The response must be valid JSON in this format:
{{
    "patches": [
        {{
            "file_path": "path/to/file.py",
            "action": "modify",
            "content": "file content here",
            "description": "What this patch does"
        }}
    ],
    "summary": "Brief summary of the overall plan"
}}

Respond with ONLY the JSON, no additional text.
"""
        return prompt.strip()
    
    def _validate_plan_structure(self, plan: Dict[str, Any]) -> Optional[str]:
        """
        Validate the structure of a generated plan.
        
        Args:
            plan: The plan dictionary to validate
            
        Returns:
            Error message if invalid, None if valid
        """
        if not isinstance(plan, dict):
            return "Plan must be a dictionary"
        
        if 'patches' not in plan:
            return "Plan must contain 'patches' key"
        
        if not isinstance(plan['patches'], list):
            return "Patches must be a list"
        
        for i, patch in enumerate(plan['patches']):
            if not isinstance(patch, dict):
                return f"Patch {i} must be a dictionary"
            
            required_keys = ['file_path', 'action', 'description']
            for key in required_keys:
                if key not in patch:
                    return f"Patch {i} missing required key: {key}"
            
            if patch['action'] not in ['create', 'modify', 'delete']:
                return f"Patch {i} has invalid action: {patch['action']}"
            
            if patch['action'] in ['create', 'modify'] and 'content' not in patch:
                return f"Patch {i} with action '{patch['action']}' must have 'content'"
        
        return None
    
    async def _load_project_manifest(self) -> str:
        """
        Load the project manifest.
        
        Returns:
            Project manifest as string
        """
        # This is a simplified version for the pilot
        # In the real implementation, this would read from files
        
        return """
Project: Hephaestus Agent
Type: Python Package
Structure:
- src/hephaestus/ (main package)
- config/ (configuration files)
- tests/ (test files)
- docs/ (documentation)

Key Components:
- Core agents in src/hephaestus/agents/
- Utilities in src/hephaestus/utils/
- Services in src/hephaestus/services/
"""
    
    async def analyze_codebase(self, target_files: list = None) -> Dict[str, Any]:
        """
        Analyze the codebase structure and dependencies.
        
        Args:
            target_files: Optional list of specific files to analyze
            
        Returns:
            Analysis results dictionary
        """
        return await self.execute_with_metrics(
            "analyze_codebase",
            self._perform_codebase_analysis,
            target_files
        )
    
    async def _perform_codebase_analysis(self, target_files: list = None) -> Dict[str, Any]:
        """Perform the actual codebase analysis."""
        # Simplified analysis for pilot
        return {
            'total_files': 50,  # Mock data
            'python_files': 45,
            'config_files': 5,
            'target_files': target_files or [],
            'analysis_timestamp': self.get_config_value('analysis.timestamp', 'now'),
        }
    
    def get_architecture_recommendations(self) -> Dict[str, Any]:
        """Get architecture recommendations based on current codebase."""
        recommendations = self.get_cached_result("architecture_recommendations")
        
        if not recommendations:
            recommendations = {
                'modularity_score': 8.5,
                'coupling_level': 'moderate',
                'recommendations': [
                    'Consider extracting common utilities',
                    'Implement dependency injection',
                    'Add more comprehensive testing'
                ],
                'priority_areas': [
                    'Agent coordination',
                    'Configuration management',
                    'Error handling'
                ]
            }
            
            # Cache for 1 hour
            self.set_cached_result("architecture_recommendations", recommendations, 3600)
        
        return recommendations