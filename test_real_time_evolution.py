#!/usr/bin/env python3
"""
‚ö° Test script for Real-Time Evolution Engine

This script tests the Real-Time Evolution Engine to verify:
1. Continuous mutation generation
2. Parallel mutation testing
3. Fitness evaluation and deployment
4. Hot-upgrade capabilities
5. Performance monitoring
"""

import sys
import logging
import asyncio
import time
import json
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from hephaestus.intelligence.real_time_evolution_engine import (
    get_real_time_evolution_engine, 
    MutationType, 
    EvolutionPhase,
    EvolutionCandidate
)
from hephaestus.utils.config_loader import load_config

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_evolution_engine():
    """Test the Real-Time Evolution Engine comprehensively"""
    
    print("‚ö° TESTING REAL-TIME EVOLUTION ENGINE")
    print("=" * 50)
    
    # Load config
    config = load_config()
    
    # Get engine
    engine = get_real_time_evolution_engine(config, logger)
    
    # Test 1: Basic Status
    print("\nüîç Test 1: Basic Status Check")
    print("-" * 30)
    
    status = engine.get_evolution_status()
    print(f"  ‚Ä¢ Evolution enabled: {status['evolution_enabled']}")
    print(f"  ‚Ä¢ Current phase: {status['current_phase']}")
    print(f"  ‚Ä¢ Active candidates: {status['active_candidates']}")
    print(f"  ‚Ä¢ Active tests: {status['active_tests']}")
    print(f"  ‚Ä¢ Deployed mutations: {status['deployed_mutations']}")
    
    # Test 2: Mutation Generation
    print("\nüß¨ Test 2: Mutation Generation")
    print("-" * 30)
    
    initial_candidates = len(engine.evolution_candidates)
    engine._generate_mutations()
    new_candidates = len(engine.evolution_candidates) - initial_candidates
    
    print(f"  ‚Ä¢ Generated {new_candidates} new mutation candidates")
    
    if engine.evolution_candidates:
        candidate = list(engine.evolution_candidates.values())[0]
        print(f"  ‚Ä¢ Sample candidate: {candidate.description[:80]}...")
        print(f"  ‚Ä¢ Mutation type: {candidate.mutation_type.value}")
        print(f"  ‚Ä¢ Risk level: {candidate.risk_level:.2f}")
    
    # Test 3: Performance Monitoring
    print("\nüìä Test 3: Performance Monitoring")
    print("-" * 30)
    
    engine._monitor_performance()
    
    if engine.performance_history:
        latest_metrics = engine.performance_history[-1]["metrics"]
        print(f"  ‚Ä¢ Success rate: {latest_metrics['success_rate']:.1%}")
        print(f"  ‚Ä¢ Avg execution time: {latest_metrics['average_execution_time']:.1f}s")
        print(f"  ‚Ä¢ Error rate: {latest_metrics['error_rate']:.1%}")
        print(f"  ‚Ä¢ Memory usage: {latest_metrics['memory_usage']:.1%}")
        print(f"  ‚Ä¢ Agent efficiency: {latest_metrics['agent_efficiency']:.1%}")
    
    # Test 4: Async Mutation Testing (simulation)
    print("\nüß™ Test 4: Async Mutation Testing")
    print("-" * 30)
    
    async def test_async_mutations():
        # Get a candidate to test
        if engine.evolution_candidates:
            candidate = list(engine.evolution_candidates.values())[0]
            print(f"  ‚Ä¢ Testing candidate: {candidate.description[:50]}...")
            
            # Simulate async testing
            await engine._test_single_mutation(candidate)
            
            print(f"  ‚Ä¢ Test completed! Fitness score: {candidate.fitness_score:.3f}")
            print(f"  ‚Ä¢ Success rate: {candidate.success_rate:.1%}")
            print(f"  ‚Ä¢ Performance impact: {candidate.performance_impact:.3f}")
            
            return candidate
        else:
            print("  ‚Ä¢ No candidates available for testing")
            return None
    
    # Run async test
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    tested_candidate = loop.run_until_complete(test_async_mutations())
    
    # Test 5: Evaluation and Deployment
    print("\nüöÄ Test 5: Evaluation and Deployment")
    print("-" * 30)
    
    if tested_candidate:
        # Artificially set a high fitness score for testing
        tested_candidate.fitness_score = 0.8
        tested_candidate.risk_level = 0.1  # Low risk
        
        engine._evaluate_mutations()
        engine._deploy_best_mutations()
        
        final_status = engine.get_evolution_status()
        print(f"  ‚Ä¢ Final deployed mutations: {final_status['deployed_mutations']}")
        print(f"  ‚Ä¢ Best fitness score: {final_status['metrics']['best_fitness_score']:.3f}")
    
    # Test 6: Best Mutations Report
    print("\nüèÜ Test 6: Best Mutations Report")
    print("-" * 30)
    
    best_mutations = engine.get_best_mutations(limit=3)
    for i, mutation in enumerate(best_mutations, 1):
        print(f"  ‚Ä¢ #{i}: {mutation['description'][:60]}...")
        print(f"    Fitness: {mutation['fitness_score']:.3f}, Risk: {mutation['risk_level']:.2f}")
    
    # Test 7: Emergency Evolution
    print("\nüö® Test 7: Emergency Evolution Trigger")
    print("-" * 30)
    
    # Simulate performance degradation
    original_baseline = engine.baseline_performance.copy()
    engine.baseline_performance = {
        "success_rate": 0.8,
        "average_execution_time": 30.0,
        "error_rate": 0.1,
        "memory_usage": 0.3,
        "agent_efficiency": 0.7
    }
    
    # Simulate poor current performance
    poor_metrics = {
        "success_rate": 0.4,  # Much lower
        "average_execution_time": 60.0,  # Much higher
        "error_rate": 0.4,  # Much higher
        "memory_usage": 0.8,  # Much higher
        "agent_efficiency": 0.3  # Much lower
    }
    
    delta = engine._calculate_performance_delta(poor_metrics)
    print(f"  ‚Ä¢ Performance delta: {delta:.1%}")
    
    if delta < -0.2:
        print("  ‚Ä¢ üö® Emergency evolution would be triggered!")
        engine._trigger_emergency_evolution()
        emergency_mutations = [c for c in engine.evolution_candidates.values() 
                             if c.candidate_id.startswith("emergency_")]
        print(f"  ‚Ä¢ Generated {len(emergency_mutations)} emergency mutations")
    
    # Restore original baseline
    engine.baseline_performance = original_baseline
    
    # Test 8: State Persistence
    print("\nüíæ Test 8: State Persistence")
    print("-" * 30)
    
    state_file = engine.save_evolution_state()
    print(f"  ‚Ä¢ Evolution state saved to: {state_file}")
    
    # Verify the saved file
    if state_file.exists():
        with open(state_file, 'r') as f:
            saved_state = json.load(f)
        
        print(f"  ‚Ä¢ Saved state contains {len(saved_state.keys())} top-level keys")
        print(f"  ‚Ä¢ Best mutations in state: {len(saved_state.get('best_mutations', []))}")
        print(f"  ‚Ä¢ Performance history entries: {len(saved_state.get('performance_history', []))}")
    
    # Test 9: Callback Registration
    print("\nüìã Test 9: Callback Registration")
    print("-" * 30)
    
    callback_test_results = {}
    
    def test_callback(mutation_data):
        callback_test_results["called"] = True
        callback_test_results["data"] = mutation_data
        return True
    
    engine.register_mutation_callback(MutationType.PROMPT_OPTIMIZATION, test_callback)
    
    # Test the callback
    test_mutation_data = {"target": "test", "modification": "test modification"}
    success = engine._deploy_mutation(EvolutionCandidate(
        candidate_id="test_callback",
        mutation_type=MutationType.PROMPT_OPTIMIZATION,
        description="Test callback",
        mutation_data=test_mutation_data
    ))
    
    print(f"  ‚Ä¢ Callback registration test: {'‚úÖ SUCCESS' if callback_test_results.get('called') else '‚ùå FAILED'}")
    print(f"  ‚Ä¢ Deployment success: {'‚úÖ YES' if success else '‚ùå NO'}")
    
    # Final Status
    print("\nüìà Final Evolution Engine Status")
    print("-" * 30)
    
    final_status = engine.get_evolution_status()
    metrics = final_status["metrics"]
    
    print(f"  ‚Ä¢ Total mutations generated: {metrics['total_mutations_generated']}")
    print(f"  ‚Ä¢ Total mutations tested: {metrics['total_mutations_tested']}")
    print(f"  ‚Ä¢ Total mutations deployed: {metrics['total_mutations_deployed']}")
    print(f"  ‚Ä¢ Successful deployments: {metrics['successful_deployments']}")
    print(f"  ‚Ä¢ Evolution uptime: {metrics['evolution_uptime']:.1f}s")
    print(f"  ‚Ä¢ Best fitness score: {metrics['best_fitness_score']:.3f}")
    
    print("\nüéâ All Real-Time Evolution Engine tests completed!")
    print("=" * 50)
    
    return engine

def test_continuous_evolution():
    """Test the engine running continuously for a short period"""
    
    print("\n‚è±Ô∏è TESTING CONTINUOUS EVOLUTION (30 seconds)")
    print("=" * 50)
    
    config = load_config()
    engine = get_real_time_evolution_engine(config, logger)
    
    # Start evolution
    engine.start_evolution()
    print("üöÄ Evolution started...")
    
    # Let it run for 30 seconds
    start_time = time.time()
    duration = 30  # seconds
    
    while time.time() - start_time < duration:
        status = engine.get_evolution_status()
        print(f"Phase: {status['current_phase']}, "
              f"Candidates: {status['active_candidates']}, "
              f"Tests: {status['active_tests']}")
        time.sleep(5)
    
    # Stop evolution
    engine.stop_evolution()
    print("üõë Evolution stopped")
    
    # Final report
    final_status = engine.get_evolution_status()
    metrics = final_status["metrics"]
    
    print(f"\nüìä Results after {duration} seconds:")
    print(f"  ‚Ä¢ Mutations generated: {metrics['total_mutations_generated']}")
    print(f"  ‚Ä¢ Mutations tested: {metrics['total_mutations_tested']}")
    print(f"  ‚Ä¢ Mutations deployed: {metrics['total_mutations_deployed']}")
    print(f"  ‚Ä¢ Evolution uptime: {metrics['evolution_uptime']:.1f}s")

if __name__ == "__main__":
    # Run comprehensive tests
    engine = test_evolution_engine()
    
    # Ask user if they want to test continuous evolution
    print("\n" + "="*50)
    response = input("ü§î Would you like to test continuous evolution for 30 seconds? (y/N): ")
    
    if response.lower().startswith('y'):
        test_continuous_evolution()
    
    print("\n‚úÖ All tests completed successfully!")